{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b137447-6259-466b-8a41-8ae4d4c32429",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning\n",
    "\n",
    "코드 출처 : https://github.com/perrying/realistic-ssl-evaluation-pytorch\n",
    "\n",
    "본 튜토리얼은 위의 코드를 참고하여 작성 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f229954-02a0-4d63-930a-8438a5bb0f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ykio\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import argparse, math, time, json, os\n",
    "\n",
    "from lib import wrn, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d253bf9-38ab-49db-b700-47454adb0f07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Dataset 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6132c523-7bd4-46ae-8d18-ad25e19337c5",
   "metadata": {},
   "source": [
    "<img src=https://user-images.githubusercontent.com/35906602/209686848-82a1e67e-33dd-4036-aaf9-26493b442a0b.png width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba4cd2-f913-4122-8672-51164a660a2e",
   "metadata": {},
   "source": [
    "* 이미지 출처 : https://gruuuuu.github.io/machine-learning/cifar10-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c61a05-0b02-4d6a-be94-14b4f761395b",
   "metadata": {},
   "source": [
    "본 튜토리얼에서는 Cifar-10 데이터셋이 활용되었습니다. Cifar-10 데이터셋은 32x32 픽셀의 60,000개의 컬러 이미지로 구성된 데이터로, 각 이미지는 총 10개의 클래스로 라벨링 되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e6d8f2-b4a6-4d88-a952-465c34830ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ykio\\lib\\site-packages\\ipykernel_launcher.py:57: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import argparse, os\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", \"-s\", default=1, type=int, help=\"random seed\")\n",
    "parser.add_argument(\"--dataset\", \"-d\", default=\"cifar10\", type=str, help=\"dataset name : [cifar10]\") # Cifar10 사용\n",
    "parser.add_argument(\"--nlabels\", \"-n\", default=1000, type=int, help=\"the number of labeled data\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "COUNTS = {\n",
    "    \"cifar10\": {\"train\": 50000, \"test\": 10000, \"valid\": 5000, \"extra\": 0},\n",
    "    \"imagenet_32\": {\n",
    "        \"train\": 1281167,\n",
    "        \"test\": 50000,\n",
    "        \"valid\": 50050,\n",
    "        \"extra\": 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "_DATA_DIR = \"./data\"\n",
    "\n",
    "def split_l_u(train_set, n_labels):\n",
    "    # NOTE: this function assume that train_set is shuffled.\n",
    "    images = train_set[\"images\"]\n",
    "    labels = train_set[\"labels\"]\n",
    "    classes = np.unique(labels)\n",
    "    n_labels_per_cls = n_labels // len(classes)\n",
    "    l_images = []\n",
    "    l_labels = []\n",
    "    u_images = []\n",
    "    u_labels = []\n",
    "    for c in classes:\n",
    "        cls_mask = (labels == c)\n",
    "        c_images = images[cls_mask]\n",
    "        c_labels = labels[cls_mask]\n",
    "        l_images += [c_images[:n_labels_per_cls]]\n",
    "        l_labels += [c_labels[:n_labels_per_cls]]\n",
    "        u_images += [c_images[n_labels_per_cls:]]\n",
    "        u_labels += [np.zeros_like(c_labels[n_labels_per_cls:]) - 1] # dammy label\n",
    "    l_train_set = {\"images\": np.concatenate(l_images, 0), \"labels\": np.concatenate(l_labels, 0)}\n",
    "    u_train_set = {\"images\": np.concatenate(u_images, 0), \"labels\": np.concatenate(u_labels, 0)}\n",
    "    return l_train_set, u_train_set\n",
    "\n",
    "def _load_cifar10():\n",
    "    splits = {}\n",
    "    for train in [True, False]:\n",
    "        tv_data = datasets.CIFAR10(_DATA_DIR, train, download=True)\n",
    "        data = {}\n",
    "        data[\"images\"] = tv_data.data\n",
    "        data[\"labels\"] = np.array(tv_data.targets)\n",
    "        splits[\"train\" if train else \"test\"] = data\n",
    "    return splits.values()\n",
    "\n",
    "def gcn(images, multiplier=55, eps=1e-10):\n",
    "    # global contrast normalization\n",
    "    images = images.astype(np.float)\n",
    "    images -= images.mean(axis=(1,2,3), keepdims=True)\n",
    "    per_image_norm = np.sqrt(np.square(images).sum((1,2,3), keepdims=True))\n",
    "    per_image_norm[per_image_norm < eps] = 1\n",
    "    return multiplier * images / per_image_norm\n",
    "\n",
    "def get_zca_normalization_param(images, scale=0.1, eps=1e-10):\n",
    "    n_data, height, width, channels = images.shape\n",
    "    images = images.reshape(n_data, height*width*channels)\n",
    "    image_cov = np.cov(images, rowvar=False)\n",
    "    U, S, _ = np.linalg.svd(image_cov + scale * np.eye(image_cov.shape[0]))\n",
    "    zca_decomp = np.dot(U, np.dot(np.diag(1/np.sqrt(S + eps)), U.T))\n",
    "    mean = images.mean(axis=0)\n",
    "    return mean, zca_decomp\n",
    "\n",
    "def zca_normalization(images, mean, decomp):\n",
    "    n_data, height, width, channels = images.shape\n",
    "    images = images.reshape(n_data, -1)\n",
    "    images = np.dot((images - mean), decomp)\n",
    "    return images.reshape(n_data, height, width, channels)\n",
    "\n",
    "rng = np.random.RandomState(args.seed)\n",
    "\n",
    "validation_count = COUNTS[args.dataset][\"valid\"]\n",
    "\n",
    "extra_set = None  # In general, there won't be extra data.\n",
    "\n",
    "train_set, test_set = _load_cifar10()\n",
    "train_set[\"images\"] = gcn(train_set[\"images\"])\n",
    "test_set[\"images\"] = gcn(test_set[\"images\"])\n",
    "mean, zca_decomp = get_zca_normalization_param(train_set[\"images\"])\n",
    "train_set[\"images\"] = zca_normalization(train_set[\"images\"], mean, zca_decomp)\n",
    "test_set[\"images\"] = zca_normalization(test_set[\"images\"], mean, zca_decomp)\n",
    "# N x H x W x C -> N x C x H x W\n",
    "train_set[\"images\"] = np.transpose(train_set[\"images\"], (0,3,1,2))\n",
    "test_set[\"images\"] = np.transpose(test_set[\"images\"], (0,3,1,2))\n",
    "\n",
    "# permute index of training set\n",
    "indices = rng.permutation(len(train_set[\"images\"]))\n",
    "train_set[\"images\"] = train_set[\"images\"][indices]\n",
    "train_set[\"labels\"] = train_set[\"labels\"][indices]\n",
    "\n",
    "if extra_set is not None:\n",
    "    extra_indices = rng.permutation(len(extra_set[\"images\"]))\n",
    "    extra_set[\"images\"] = extra_set[\"images\"][extra_indices]\n",
    "    extra_set[\"labels\"] = extra_set[\"labels\"][extra_indices]\n",
    "\n",
    "# split training set into training and validation\n",
    "train_images = train_set[\"images\"][validation_count:]\n",
    "train_labels = train_set[\"labels\"][validation_count:]\n",
    "validation_images = train_set[\"images\"][:validation_count]\n",
    "validation_labels = train_set[\"labels\"][:validation_count]\n",
    "validation_set = {\"images\": validation_images, \"labels\": validation_labels}\n",
    "train_set = {\"images\": train_images, \"labels\": train_labels}\n",
    "\n",
    "# split training set into labeled data and unlabeled data\n",
    "l_train_set, u_train_set = split_l_u(train_set, args.nlabels)\n",
    "\n",
    "if not os.path.exists(os.path.join(_DATA_DIR, args.dataset)):\n",
    "    os.mkdir(os.path.join(_DATA_DIR, args.dataset))\n",
    "\n",
    "np.save(os.path.join(_DATA_DIR, args.dataset, \"l_train\"), l_train_set)\n",
    "np.save(os.path.join(_DATA_DIR, args.dataset, \"u_train\"), u_train_set)\n",
    "np.save(os.path.join(_DATA_DIR, args.dataset, \"val\"), validation_set)\n",
    "np.save(os.path.join(_DATA_DIR, args.dataset, \"test\"), test_set)\n",
    "if extra_set is not None:\n",
    "    np.save(os.path.join(_DATA_DIR, args.dataset, \"extra\"), extra_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0283353-97cf-410d-bc02-5e8f99f2c44d",
   "metadata": {},
   "source": [
    "## 00. 공통 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747038e2-6c77-4cf3-a51f-f377d5716d2b",
   "metadata": {},
   "source": [
    "밑의 파라미터는 모든 학습에서 공유하게 됩니다. \n",
    "\n",
    "기존에는 50만 이상의 많은 수의 Iteration을 필요로 하나, 학습 시간의 문제로 본 튜토리얼에서는 10,000번의 Iteration으로 학습하게 됩니다. 따라서 기존에 알려진 성능보다 낮은 성능을 보인다는 점을 주의해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e93f5fd-3759-4045-a7e1-dd23439603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41ed093-4739-49a8-8c11-9f3029b13ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--alg\", \"-a\", default=\"VAT\", type=str, help=\"ssl algorithm : [supervised, PI, MT, VAT, PL, ICT]\")\n",
    "parser.add_argument(\"--em\", default=0, type=float, help=\"coefficient of entropy minimization. If you try VAT + EM, set 0.06\")\n",
    "parser.add_argument(\"--validation\", default=1000, type=int, help=\"validate at this interval (default 25000)\")\n",
    "parser.add_argument(\"--dataset\", \"-d\", default=\"cifar10\", type=str, help=\"dataset name : [cifar10]\")\n",
    "parser.add_argument(\"--root\", \"-r\", default=\"data\", type=str, help=\"dataset dir\")\n",
    "parser.add_argument(\"--output\", \"-o\", default=\"./exp_res\", type=str, help=\"output dir\")\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66010b32-e2c4-4604-93e4-e079555101d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_config = {\n",
    "    \"iteration\" : 10000,\n",
    "    \"warmup\" : 4000,\n",
    "    \"lr_decay_iter\" : 8000,\n",
    "    \"lr_decay_factor\" : 0.2,\n",
    "    \"batch_size\" : 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d930ccc-91c4-4d51-a1de-cbad84b0af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSampler(torch.utils.data.Sampler):\n",
    "    \"\"\" sampling without replacement \"\"\"\n",
    "    def __init__(self, num_data, num_sample):\n",
    "        iterations = num_sample // num_data + 1\n",
    "        self.indices = torch.cat([torch.randperm(num_data) for _ in range(iterations)]).tolist()[:num_sample]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2d62a-2bcc-4035-9b9c-421fa45d5cc2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f298c1-0428-4eb5-8ba5-a4b11aae3e9a",
   "metadata": {},
   "source": [
    "딥러닝 모델을 학습시키기 위한 데이터셋을 구성하는 단계입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7302c213-3d8b-4442-9b3f-420b5c736801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10:\n",
    "    def __init__(self, root, split=\"l_train\"):\n",
    "        self.dataset = np.load(os.path.join(root, \"cifar10\", split+\".npy\"), allow_pickle=True).item()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[\"images\"][idx]\n",
    "        label = self.dataset[\"labels\"][idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d4fe10-a1d4-4802-8880-08c4bd667819",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_config = {\n",
    "    \"transform\" : [True, True, True], # 차례대로 Horizontal flip, Random crop, Gaussian Noise를 의미합니다.\n",
    "    \"dataset\" : CIFAR10,\n",
    "    \"num_classes\" : 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e91c3e-65e2-401e-904d-15637c8e432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holizontal flip : True, random crop : True, gaussian noise : True\n",
      "labeled data : 1000, unlabeled data : 44000, training data : 45000\n",
      "validation data : 5000, test data : 10000\n"
     ]
    }
   ],
   "source": [
    "dataset_cfg = cifar10_config\n",
    "transform_fn = transform.transform(*dataset_cfg[\"transform\"])\n",
    "\n",
    "l_train_dataset = dataset_cfg[\"dataset\"](args.root, \"l_train\")\n",
    "u_train_dataset = dataset_cfg[\"dataset\"](args.root, \"u_train\")\n",
    "val_dataset = dataset_cfg[\"dataset\"](args.root, \"val\")\n",
    "test_dataset = dataset_cfg[\"dataset\"](args.root, \"test\")\n",
    "\n",
    "print(\"labeled data : {}, unlabeled data : {}, training data : {}\".format(\n",
    "    len(l_train_dataset), len(u_train_dataset), len(l_train_dataset)+len(u_train_dataset)))\n",
    "print(\"validation data : {}, test data : {}\".format(len(val_dataset), len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dea23a1-7dc8-4a5c-8e65-b4c73d257ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_loader = DataLoader(\n",
    "    l_train_dataset, shared_config[\"batch_size\"], drop_last=True,\n",
    "    sampler=RandomSampler(len(l_train_dataset), shared_config[\"iteration\"] * shared_config[\"batch_size\"])\n",
    ")\n",
    "\n",
    "u_loader = DataLoader(\n",
    "    u_train_dataset, shared_config[\"batch_size\"]//2, drop_last=True,\n",
    "    sampler=RandomSampler(len(u_train_dataset), shared_config[\"iteration\"] * shared_config[\"batch_size\"]//2)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, 128, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, 128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0b418-e850-4627-abe1-2933c86ce5bc",
   "metadata": {},
   "source": [
    "## 1. VAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d06a8b-40e1-4116-9328-47a8e96b9e48",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209687878-59d1e148-96db-4959-90ae-53096a6e8e71.png\" width=\"700\">\n",
    "\n",
    "Virtual Adversarial Training이란 Adversarial Training을 Semi-Supervised Learning에 접목한 방법론입니다. 라벨이 없는 데이터에 가상의 적대적 방향을 정의하고, 이 방향을 이용해 Adversarial Training을 수행하게 됩니다.\n",
    "\n",
    "참고 : https://creamnuts.github.io/short%20review/vat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee37516-4380-45d8-92dd-0617a8dfe88b",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a29918-24e2-490c-8f79-118cca17b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alg = 'VAT'\n",
    "vat_config = {\n",
    "    # virtual adversarial training\n",
    "    \"xi\" : 1e-6,\n",
    "    \"eps\" : {\"cifar10\":6},\n",
    "    \"consis_coef\" : 0.3,\n",
    "    \"lr\" : 3e-3\n",
    "}\n",
    "alg_cfg = vat_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95a3b1-c66d-4060-9cc2-2c7a4de1a146",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23842d33-2dab-4564-b0ec-ee9c1fd8c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAT(nn.Module):\n",
    "    def __init__(self, eps=1.0, xi=1e-6, n_iteration=1):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.xi = xi\n",
    "        self.n_iteration = n_iteration\n",
    "\n",
    "    def kld(self, q_logit, p_logit):\n",
    "        q = q_logit.softmax(1)\n",
    "        qlogp = (q * self.__logsoftmax(p_logit)).sum(1)\n",
    "        qlogq = (q * self.__logsoftmax(q_logit)).sum(1)\n",
    "        return qlogq - qlogp\n",
    "\n",
    "    def normalize(self, v):\n",
    "        v = v / (1e-12 + self.__reduce_max(v.abs(), range(1, len(v.shape))))\n",
    "        v = v / (1e-6 + v.pow(2).sum((1,2,3),keepdim=True)).sqrt()\n",
    "        return v\n",
    "\n",
    "    def forward(self, x, y, model, mask):\n",
    "        model.update_batch_stats(False)\n",
    "        d = torch.randn_like(x)\n",
    "        d = self.normalize(d)\n",
    "        for _ in range(self.n_iteration):\n",
    "            d.requires_grad = True\n",
    "            x_hat = x + self.xi * d\n",
    "            y_hat = model(x_hat)\n",
    "            kld = self.kld(y.detach(), y_hat).mean()\n",
    "            d = torch.autograd.grad(kld, d)[0]\n",
    "            d = self.normalize(d).detach()\n",
    "        x_hat = x + self.eps * d\n",
    "        y_hat = model(x_hat)\n",
    "        # NOTE:\n",
    "        # Original implimentation of VAT defines KL(P(y|x)||P(x|x+r_adv)) as loss function\n",
    "        # However, Avital Oliver's implimentation use KL(P(y|x+r_adv)||P(y|x)) as loss function of VAT\n",
    "        # see issue https://github.com/brain-research/realistic-ssl-evaluation/issues/27\n",
    "        loss = (self.kld(y_hat, y.detach()) * mask).mean()\n",
    "        model.update_batch_stats(True)\n",
    "        return loss\n",
    "\n",
    "    def __reduce_max(self, v, idx_list):\n",
    "        for i in idx_list:\n",
    "            v = v.max(i, keepdim=True)[0]\n",
    "        return v\n",
    "\n",
    "    def __logsoftmax(self,x):\n",
    "        xdev = x - x.max(1, keepdim=True)[0]\n",
    "        lsm = xdev - xdev.exp().sum(1, keepdim=True).log()\n",
    "        return lsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c6f2f2-0bc2-4bc5-a243-8dd07fc0e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters : 1467610\n"
     ]
    }
   ],
   "source": [
    "model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alg_cfg[\"lr\"])\n",
    "\n",
    "trainable_paramters = sum([p.data.nelement() for p in model.parameters()])\n",
    "print(\"trainable parameters : {}\".format(trainable_paramters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a50f7-80e4-4ca7-9191-039c4da44e4d",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209687686-e6183eae-6877-4d58-af50-f76481117eb9.png\" width=\"800\">\n",
    "\n",
    "지도학습 모델은 WideResnet을 사용하게 됩니다. 이 튜토리얼에서는 SSL 방법론의 성능을 비교하기 위해 VAT를 비롯한 5개 SSL 모델 모두에서 해당 모델을 Backbone 모델로 통일하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521f4b46-d9f4-4a90-a7fb-c4c8f3af2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_obj = VAT(alg_cfg[\"eps\"][args.dataset], alg_cfg[\"xi\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8372e9-0ed3-4b03-ab92-a1ff23d873f0",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615864a8-a45e-406a-b088-2f2e179b3f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1000/10000] cls loss : 1.036135e-02, SSL loss : 1.539129e-02, coef : 1.80164e-02, time : 13.852 iter/sec, rest : 10.829 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 149.1 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.5533999800682068\n",
      "### test ###\n",
      "[70/79] time : 1537.1 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.5339999794960022\n",
      "iteration [2000/10000] cls loss : 2.781086e-02, SSL loss : 6.056770e-02, coef : 8.59514e-02, time : 12.757 iter/sec, rest : 10.452 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 153.7 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.5149999856948853\n",
      "iteration [3000/10000] cls loss : 1.537405e-02, SSL loss : 2.573695e-01, coef : 2.19485e-01, time : 13.394 iter/sec, rest : 8.710 min, lr : 0.003  \n",
      "### validation ###\n",
      "[40/40] time : 146.9 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.5491999983787537\n",
      "iteration [4000/10000] cls loss : 3.041661e-02, SSL loss : 1.678324e-01, coef : 3.00000e-01, time : 13.083 iter/sec, rest : 7.644 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 153.7 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6039999723434448\n",
      "### test ###\n",
      "[70/79] time : 1427.3 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.6029999852180481\n",
      "iteration [5000/10000] cls loss : 3.926447e-03, SSL loss : 1.888154e-01, coef : 3.00000e-01, time : 13.726 iter/sec, rest : 6.071 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 151.4 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6146000027656555\n",
      "### test ###\n",
      "[70/79] time : 1448.0 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.6168000102043152\n",
      "iteration [6000/10000] cls loss : 1.786569e-02, SSL loss : 2.593825e-01, coef : 3.00000e-01, time : 13.612 iter/sec, rest : 4.898 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 142.2 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6003999710083008\n",
      "iteration [7000/10000] cls loss : 9.963264e-02, SSL loss : 2.002419e-01, coef : 3.00000e-01, time : 13.177 iter/sec, rest : 3.795 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 147.1 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6207999587059021\n",
      "### test ###\n",
      "[70/79] time : 1297.5 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.618399977684021\n",
      "iteration [8000/10000] cls loss : 1.960606e-02, SSL loss : 2.432467e-01, coef : 3.00000e-01, time : 12.830 iter/sec, rest : 2.598 min, lr : 0.003 \n",
      "### validation ###\n",
      "[40/40] time : 136.9 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6335999965667725\n",
      "### test ###\n",
      "[70/79] time : 1317.5 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.6347999572753906\n",
      "iteration [9000/10000] cls loss : 9.525108e-03, SSL loss : 1.491355e-01, coef : 3.00000e-01, time : 13.399 iter/sec, rest : 1.244 min, lr : 0.0006000000000000001 \n",
      "### validation ###\n",
      "[40/40] time : 136.9 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.652999997138977\n",
      "### test ###\n",
      "[70/79] time : 1411.6 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.6421999931335449\n",
      "iteration [10000/10000] cls loss : 4.005682e-04, SSL loss : 1.000803e-01, coef : 3.00000e-01, time : 13.430 iter/sec, rest : 0.000 min, lr : 0.0006000000000000001 \n",
      "### validation ###\n",
      "[40/40] time : 126.5 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.6469999551773071\n",
      "test acc : 0.6421999931335449\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "VAT_cls_loss_list = []\n",
    "VAT_ssl_loss_list = []\n",
    "VAT_loss_list = []\n",
    "\n",
    "VAT_val_acc_list = []\n",
    "###\n",
    "\n",
    "iteration = 0\n",
    "maximum_val_acc = 0\n",
    "s = time.time()\n",
    "for l_data, u_data in zip(l_loader, u_loader):\n",
    "    iteration += 1\n",
    "    l_input, target = l_data\n",
    "    l_input, target = l_input.to(device).float(), target.to(device).long()\n",
    "\n",
    "    u_input, dummy_target = u_data\n",
    "    u_input, dummy_target = u_input.to(device).float(), dummy_target.to(device).long()\n",
    "\n",
    "    target = torch.cat([target, dummy_target], 0)\n",
    "    unlabeled_mask = (target == -1).float()\n",
    "\n",
    "    inputs = torch.cat([l_input, u_input], 0)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # ramp up exp(-5(1 - t)^2)\n",
    "    coef = alg_cfg[\"consis_coef\"] * math.exp(-5 * (1 - min(iteration/shared_config[\"warmup\"], 1))**2)\n",
    "    ssl_loss = ssl_obj(inputs, outputs.detach(), model, unlabeled_mask) * coef\n",
    "\n",
    "    # supervised loss\n",
    "    cls_loss = F.cross_entropy(outputs, target, reduction=\"none\", ignore_index=-1).mean()\n",
    "\n",
    "    loss = cls_loss + ssl_loss\n",
    "    \n",
    "    ###\n",
    "    VAT_cls_loss_list.append(cls_loss)\n",
    "    VAT_ssl_loss_list.append(ssl_loss)\n",
    "    VAT_loss_list.append(loss)\n",
    "    ###\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 표기\n",
    "    if iteration == 1 or (iteration % 100) == 0:\n",
    "        wasted_time = time.time() - s\n",
    "        rest = (shared_config[\"iteration\"] - iteration)/100 * wasted_time / 60\n",
    "        print(\"iteration [{}/{}] cls loss : {:.6e}, SSL loss : {:.6e}, coef : {:.5e}, time : {:.3f} iter/sec, rest : {:.3f} min, lr : {}\".format(\n",
    "            iteration, shared_config[\"iteration\"], cls_loss.item(), ssl_loss.item(), coef, 100 / wasted_time, rest, optimizer.param_groups[0][\"lr\"]),\n",
    "            \"\\r\", end=\"\")\n",
    "        s = time.time()\n",
    "        \n",
    "    # Validation\n",
    "    if (iteration % args.validation) == 0 or iteration == shared_config[\"iteration\"]:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            print()\n",
    "            print(\"### validation ###\")\n",
    "            sum_acc = 0.\n",
    "            s = time.time()\n",
    "            for j, data in enumerate(val_loader):\n",
    "                input, target = data\n",
    "                input, target = input.to(device).float(), target.to(device).long()\n",
    "\n",
    "                output = model(input)\n",
    "\n",
    "                pred_label = output.max(1)[1]\n",
    "                sum_acc += (pred_label == target).float().sum()\n",
    "                if ((j+1) % 10) == 0:\n",
    "                    d_p_s = 10/(time.time()-s)\n",
    "                    print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                        j+1, len(val_loader), d_p_s, (len(val_loader) - j-1)/d_p_s\n",
    "                    ), \"\\r\", end=\"\")\n",
    "                    s = time.time()\n",
    "            acc = sum_acc/float(len(val_dataset))\n",
    "            print()\n",
    "            print(\"varidation accuracy : {}\".format(acc))\n",
    "            \n",
    "            ###\n",
    "            VAT_val_acc_list.append(acc)\n",
    "            ###\n",
    "            \n",
    "            # Test\n",
    "            if maximum_val_acc < acc:\n",
    "                print(\"### test ###\")\n",
    "                maximum_val_acc = acc\n",
    "                sum_acc = 0.\n",
    "                s = time.time()\n",
    "                for j, data in enumerate(test_loader):\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device).float(), target.to(device).long()\n",
    "                    output = model(input)\n",
    "                    pred_label = output.max(1)[1]\n",
    "                    sum_acc += (pred_label == target).float().sum()\n",
    "                    if ((j+1) % 10) == 0:\n",
    "                        d_p_s = 100/(time.time()-s)\n",
    "                        print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                            j+1, len(test_loader), d_p_s, (len(test_loader) - j-1)/d_p_s\n",
    "                        ), \"\\r\", end=\"\")\n",
    "                        s = time.time()\n",
    "                print()\n",
    "                test_acc = sum_acc / float(len(test_dataset))\n",
    "                print(\"test accuracy : {}\".format(test_acc))\n",
    "                # torch.save(model.state_dict(), os.path.join(args.output, \"best_model.pth\"))\n",
    "        model.train()\n",
    "        s = time.time()\n",
    "        \n",
    "    # lr decay\n",
    "    if iteration == shared_config[\"lr_decay_iter\"]:\n",
    "        optimizer.param_groups[0][\"lr\"] *= shared_config[\"lr_decay_factor\"]    \n",
    "        \n",
    "print(\"test acc : {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854fd4e-5d7d-429e-bbe9-73a0dd2ebe65",
   "metadata": {},
   "source": [
    "## 2. Mean Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769040dc-9508-45c4-bde4-f4953763e6a1",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209688575-a6512a9a-9f4d-43eb-884e-b105c70e1477.png\" width=\"1000\">\n",
    "\n",
    "* Reference : https://nuguziii.github.io/paper-review/PR-009/\n",
    "* Tarvainen and Valpora. Mean teachers are better role models: Weighted-averaged consistency targets improve semi-supervised deep learning results. NIPS 2017\n",
    "\n",
    "같은 구조를 가지는 2개의 모델 student model과 teacher model이 존재하며, Student model은 labeled data를 Input으로 받으며, teacher model은 unlabeled data를 Input으로 받게 됩니다. \n",
    "\n",
    "Student model은 지도 학습 기반의 손실 함수 및 teacher model과의 consistency loss로 학습이 되며, teacher model은 student model의 parameter를 지수 이동 평균하여 update하기 때문에 역전파가 진행되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c36908b-258a-4d38-836e-eb820c1f8e0b",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36a7348-500f-4b71-9bb9-d4e4c5264545",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alg = 'MT'\n",
    "mt_config = {\n",
    "    # mean teacher\n",
    "    \"ema_factor\" : 0.95,\n",
    "    \"lr\" : 4e-4,\n",
    "    \"consis_coef\" : 8,\n",
    "}\n",
    "alg_cfg = mt_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718b0d9-71c9-4879-b47d-a367776dedbe",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cad27df-d899-439a-b65d-9cd6dee51c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MT(nn.Module):\n",
    "    def __init__(self, model, ema_factor):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.train()\n",
    "        self.ema_factor = ema_factor\n",
    "        self.global_step = 0\n",
    "\n",
    "    def forward(self, x, y, model, mask):\n",
    "        self.global_step += 1\n",
    "        y_hat = self.model(x)\n",
    "        model.update_batch_stats(False)\n",
    "        y = model(x) # recompute y since y as input of forward function is detached\n",
    "        model.update_batch_stats(True)\n",
    "        return (F.mse_loss(y.softmax(1), y_hat.softmax(1).detach(), reduction=\"none\").mean(1) * mask).mean()\n",
    "\n",
    "    def moving_average(self, parameters):\n",
    "        ema_factor = min(1 - 1 / (self.global_step+1), self.ema_factor)\n",
    "        for emp_p, p in zip(self.model.parameters(), parameters):\n",
    "            emp_p.data = ema_factor * emp_p.data + (1 - ema_factor) * p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438e0987-b2e5-40ca-9e7e-c6ae6cd4896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable parameters : 1467610\n"
     ]
    }
   ],
   "source": [
    "model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alg_cfg[\"lr\"])\n",
    "\n",
    "trainable_paramters = sum([p.data.nelement() for p in model.parameters()])\n",
    "print(\"trainable parameters : {}\".format(trainable_paramters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d495ec6-c542-483f-a0fe-057b1972bfbb",
   "metadata": {},
   "source": [
    "Mean Teacher는 Student 모델과 Teacher 모델이 존재하게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c32d7e-bb38-4467-83ca-a1e89105857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "t_model.load_state_dict(model.state_dict())\n",
    "ssl_obj = MT(t_model, alg_cfg[\"ema_factor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68594252-459f-46a8-afec-58d0a3cb96e5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3070d1-3d48-4600-92a1-83ad1e600b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [1000/10000] cls loss : 2.663326e-02, SSL loss : 1.042584e-02, coef : 4.80437e-01, time : 17.386 iter/sec, rest : 8.628 min, lr : 0.0004 \n",
      "### validation ###\n",
      "[40/40] time : 133.2 data/sec, rest : 0.00 sec \n",
      "varidation accuracy : 0.4883999824523926\n",
      "### test ###\n",
      "[70/79] time : 1332.1 data/sec, rest : 0.01 sec \n",
      "test accuracy : 0.4846999943256378\n",
      "iteration [1100/10000] cls loss : 3.664000e-02, SSL loss : 1.322712e-02, coef : 5.77710e-01, time : 16.441 iter/sec, rest : 9.022 min, lr : 0.0004 \r"
     ]
    }
   ],
   "source": [
    "###\n",
    "MT_cls_loss_list = []\n",
    "MT_ssl_loss_list = []\n",
    "MT_loss_list = []\n",
    "\n",
    "MT_val_acc_list = []\n",
    "###\n",
    "\n",
    "iteration = 0\n",
    "maximum_val_acc = 0\n",
    "s = time.time()\n",
    "for l_data, u_data in zip(l_loader, u_loader):\n",
    "    iteration += 1\n",
    "    l_input, target = l_data\n",
    "    l_input, target = l_input.to(device).float(), target.to(device).long()\n",
    "\n",
    "    u_input, dummy_target = u_data\n",
    "    u_input, dummy_target = u_input.to(device).float(), dummy_target.to(device).long()\n",
    "\n",
    "    target = torch.cat([target, dummy_target], 0)\n",
    "    unlabeled_mask = (target == -1).float()\n",
    "\n",
    "    inputs = torch.cat([l_input, u_input], 0)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # ramp up exp(-5(1 - t)^2)\n",
    "    coef = alg_cfg[\"consis_coef\"] * math.exp(-5 * (1 - min(iteration/shared_config[\"warmup\"], 1))**2)\n",
    "    ssl_loss = ssl_obj(inputs, outputs.detach(), model, unlabeled_mask) * coef\n",
    "\n",
    "    # supervised loss\n",
    "    cls_loss = F.cross_entropy(outputs, target, reduction=\"none\", ignore_index=-1).mean()\n",
    "\n",
    "    loss = cls_loss + ssl_loss\n",
    "    \n",
    "    ###\n",
    "    MT_cls_loss_list.append(cls_loss)\n",
    "    MT_ssl_loss_list.append(ssl_loss)\n",
    "    MT_loss_list.append(loss)\n",
    "    ###\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 표기\n",
    "    if iteration == 1 or (iteration % 100) == 0:\n",
    "        wasted_time = time.time() - s\n",
    "        rest = (shared_config[\"iteration\"] - iteration)/100 * wasted_time / 60\n",
    "        print(\"iteration [{}/{}] cls loss : {:.6e}, SSL loss : {:.6e}, coef : {:.5e}, time : {:.3f} iter/sec, rest : {:.3f} min, lr : {}\".format(\n",
    "            iteration, shared_config[\"iteration\"], cls_loss.item(), ssl_loss.item(), coef, 100 / wasted_time, rest, optimizer.param_groups[0][\"lr\"]),\n",
    "            \"\\r\", end=\"\")\n",
    "        s = time.time()\n",
    "        \n",
    "    # Validation\n",
    "    if (iteration % args.validation) == 0 or iteration == shared_config[\"iteration\"]:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            print()\n",
    "            print(\"### validation ###\")\n",
    "            sum_acc = 0.\n",
    "            s = time.time()\n",
    "            for j, data in enumerate(val_loader):\n",
    "                input, target = data\n",
    "                input, target = input.to(device).float(), target.to(device).long()\n",
    "\n",
    "                output = model(input)\n",
    "\n",
    "                pred_label = output.max(1)[1]\n",
    "                sum_acc += (pred_label == target).float().sum()\n",
    "                if ((j+1) % 10) == 0:\n",
    "                    d_p_s = 10/(time.time()-s)\n",
    "                    print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                        j+1, len(val_loader), d_p_s, (len(val_loader) - j-1)/d_p_s\n",
    "                    ), \"\\r\", end=\"\")\n",
    "                    s = time.time()\n",
    "            acc = sum_acc/float(len(val_dataset))\n",
    "            print()\n",
    "            print(\"varidation accuracy : {}\".format(acc))\n",
    "            \n",
    "            ###\n",
    "            MT_val_acc_list.append(acc)\n",
    "            ###\n",
    "            \n",
    "            # Test\n",
    "            if maximum_val_acc < acc:\n",
    "                print(\"### test ###\")\n",
    "                maximum_val_acc = acc\n",
    "                sum_acc = 0.\n",
    "                s = time.time()\n",
    "                for j, data in enumerate(test_loader):\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device).float(), target.to(device).long()\n",
    "                    output = model(input)\n",
    "                    pred_label = output.max(1)[1]\n",
    "                    sum_acc += (pred_label == target).float().sum()\n",
    "                    if ((j+1) % 10) == 0:\n",
    "                        d_p_s = 100/(time.time()-s)\n",
    "                        print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                            j+1, len(test_loader), d_p_s, (len(test_loader) - j-1)/d_p_s\n",
    "                        ), \"\\r\", end=\"\")\n",
    "                        s = time.time()\n",
    "                print()\n",
    "                test_acc = sum_acc / float(len(test_dataset))\n",
    "                print(\"test accuracy : {}\".format(test_acc))\n",
    "                # torch.save(model.state_dict(), os.path.join(args.output, \"best_model.pth\"))\n",
    "        model.train()\n",
    "        s = time.time()\n",
    "        \n",
    "    # lr decay\n",
    "    if iteration == shared_config[\"lr_decay_iter\"]:\n",
    "        optimizer.param_groups[0][\"lr\"] *= shared_config[\"lr_decay_factor\"]    \n",
    "        \n",
    "print(\"test acc : {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fce94d-132f-46dc-a57b-4d98850fb4c5",
   "metadata": {},
   "source": [
    "## 3. ${\\Pi}$ Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12405f7d-26ce-4f2e-9ae5-65afee0b67e5",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209688968-9a1acdfe-12bb-43d0-b3de-fe02c159c27e.png\" width=1000>\n",
    "\n",
    "* Reference : https://nuguziii.github.io/paper-review/PR-009/\n",
    "* Laine and Alia. Temporal Ensembling for Semi-Supervised Learning. ICLR 2017\n",
    "\n",
    "$\\Pi$ Model에서는 같은 input에 대해서는 noise가 적용되어도 비슷한 결과를 보여야 한다는 것에서 착안, stochastic augmentation을 각각 다르게 적용합니다. \n",
    "\n",
    "Stochastic Augmentation과 Dropout을 이용해 동일한 입력 $x_i$ 에서 다른 출력 $z_i$ 와 $\\tilde{z}_i$이 나타납니다.\n",
    "\n",
    "다만 Training Target이 네트워크의 하나의 evaluation에 의해 얻어지기 때문에 noisy 하다는 문제점이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6c254-ea81-4bb3-afe0-5a47fd500f34",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e9f79-ac1f-49d4-b59a-7c92ea69da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alg = 'pi'\n",
    "pi_config = {\n",
    "    # Pi Model\n",
    "    \"lr\" : 3e-4,\n",
    "    \"consis_coef\" : 20.0,\n",
    "}\n",
    "alg_cfg = pi_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3019f0c-409f-4771-9226-0b8739d3c729",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c118e-a256-4518-a835-37b872ea8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y, model, mask):\n",
    "        # NOTE:\n",
    "        # stochastic transformation is embeded in forward function\n",
    "        # so, pi-model is just to calculate consistency between two outputs\n",
    "        model.update_batch_stats(False)\n",
    "        y_hat = model(x)\n",
    "        model.update_batch_stats(True)\n",
    "        return (F.mse_loss(y_hat.softmax(1), y.softmax(1).detach(), reduction=\"none\").mean(1) * mask).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8bc9-51db-4f7e-85c4-07c162edf763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alg_cfg[\"lr\"])\n",
    "\n",
    "trainable_paramters = sum([p.data.nelement() for p in model.parameters()])\n",
    "print(\"trainable parameters : {}\".format(trainable_paramters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12df33-c6b5-4b59-991a-d2e9c8a16fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_obj = PiModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63150ad1-7c0a-4deb-805c-c57555971261",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aeb367-4736-4463-a426-5aedce3c445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "pi_cls_loss_list = []\n",
    "pi_ssl_loss_list = []\n",
    "pi_loss_list = []\n",
    "\n",
    "pi_val_acc_list = []\n",
    "###\n",
    "\n",
    "iteration = 0\n",
    "maximum_val_acc = 0\n",
    "s = time.time()\n",
    "for l_data, u_data in zip(l_loader, u_loader):\n",
    "    iteration += 1\n",
    "    l_input, target = l_data\n",
    "    l_input, target = l_input.to(device).float(), target.to(device).long()\n",
    "\n",
    "    u_input, dummy_target = u_data\n",
    "    u_input, dummy_target = u_input.to(device).float(), dummy_target.to(device).long()\n",
    "\n",
    "    target = torch.cat([target, dummy_target], 0)\n",
    "    unlabeled_mask = (target == -1).float()\n",
    "\n",
    "    inputs = torch.cat([l_input, u_input], 0)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # ramp up exp(-5(1 - t)^2)\n",
    "    coef = alg_cfg[\"consis_coef\"] * math.exp(-5 * (1 - min(iteration/shared_config[\"warmup\"], 1))**2)\n",
    "    ssl_loss = ssl_obj(inputs, outputs.detach(), model, unlabeled_mask) * coef\n",
    "\n",
    "    # supervised loss\n",
    "    cls_loss = F.cross_entropy(outputs, target, reduction=\"none\", ignore_index=-1).mean()\n",
    "\n",
    "    loss = cls_loss + ssl_loss\n",
    "    \n",
    "    ###\n",
    "    pi_cls_loss_list.append(cls_loss)\n",
    "    pi_ssl_loss_list.append(ssl_loss)\n",
    "    pi_loss_list.append(loss)\n",
    "    ###\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 표기\n",
    "    if iteration == 1 or (iteration % 100) == 0:\n",
    "        wasted_time = time.time() - s\n",
    "        rest = (shared_config[\"iteration\"] - iteration)/100 * wasted_time / 60\n",
    "        print(\"iteration [{}/{}] cls loss : {:.6e}, SSL loss : {:.6e}, coef : {:.5e}, time : {:.3f} iter/sec, rest : {:.3f} min, lr : {}\".format(\n",
    "            iteration, shared_config[\"iteration\"], cls_loss.item(), ssl_loss.item(), coef, 100 / wasted_time, rest, optimizer.param_groups[0][\"lr\"]),\n",
    "            \"\\r\", end=\"\")\n",
    "        s = time.time()\n",
    "        \n",
    "    # Validation\n",
    "    if (iteration % args.validation) == 0 or iteration == shared_config[\"iteration\"]:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            print()\n",
    "            print(\"### validation ###\")\n",
    "            sum_acc = 0.\n",
    "            s = time.time()\n",
    "            for j, data in enumerate(val_loader):\n",
    "                input, target = data\n",
    "                input, target = input.to(device).float(), target.to(device).long()\n",
    "\n",
    "                output = model(input)\n",
    "\n",
    "                pred_label = output.max(1)[1]\n",
    "                sum_acc += (pred_label == target).float().sum()\n",
    "                if ((j+1) % 10) == 0:\n",
    "                    d_p_s = 10/(time.time()-s)\n",
    "                    print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                        j+1, len(val_loader), d_p_s, (len(val_loader) - j-1)/d_p_s\n",
    "                    ), \"\\r\", end=\"\")\n",
    "                    s = time.time()\n",
    "            acc = sum_acc/float(len(val_dataset))\n",
    "            print()\n",
    "            print(\"varidation accuracy : {}\".format(acc))\n",
    "            \n",
    "            ###\n",
    "            pi_val_acc_list.append(acc)\n",
    "            ###\n",
    "            \n",
    "            # Test\n",
    "            if maximum_val_acc < acc:\n",
    "                print(\"### test ###\")\n",
    "                maximum_val_acc = acc\n",
    "                sum_acc = 0.\n",
    "                s = time.time()\n",
    "                for j, data in enumerate(test_loader):\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device).float(), target.to(device).long()\n",
    "                    output = model(input)\n",
    "                    pred_label = output.max(1)[1]\n",
    "                    sum_acc += (pred_label == target).float().sum()\n",
    "                    if ((j+1) % 10) == 0:\n",
    "                        d_p_s = 100/(time.time()-s)\n",
    "                        print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                            j+1, len(test_loader), d_p_s, (len(test_loader) - j-1)/d_p_s\n",
    "                        ), \"\\r\", end=\"\")\n",
    "                        s = time.time()\n",
    "                print()\n",
    "                test_acc = sum_acc / float(len(test_dataset))\n",
    "                print(\"test accuracy : {}\".format(test_acc))\n",
    "                # torch.save(model.state_dict(), os.path.join(args.output, \"best_model.pth\"))\n",
    "        model.train()\n",
    "        s = time.time()\n",
    "        \n",
    "    # lr decay\n",
    "    if iteration == shared_config[\"lr_decay_iter\"]:\n",
    "        optimizer.param_groups[0][\"lr\"] *= shared_config[\"lr_decay_factor\"]    \n",
    "        \n",
    "print(\"test acc : {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef93fc2-028a-4da1-9904-0d84dfa6b947",
   "metadata": {},
   "source": [
    "## 4. ICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c40a1-a859-4755-9c0c-e32ff6254a20",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209689311-5deeee55-ae48-4fcb-80e6-720febca5e03.png\" width=\"1000\">\n",
    "\n",
    "* Reference : https://jiwunghyun.medium.com/semi-supervised-learning-%EC%A0%95%EB%A6%AC-a7ed58a8f023\n",
    "* Vikas Verma et al. Interpolation Consistency Training for Semi-Supervised Learning. IJCAI 2019\n",
    "\n",
    "Mixup을 Semi-supervised learning에 적용한 방법입니다. (Mixup한 데이터에 대한 모델 결과)와 (unlabeled sample의 모델 결과의 Mixup) 차이가 consistency loss가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44dbc21-5243-41ea-81ef-1dbf0cb8015c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129187fc-78b0-479d-a532-57f5fe6ba737",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alg = 'ICT'\n",
    "ict_config = {\n",
    "    # interpolation consistency training\n",
    "    \"ema_factor\" : 0.999,\n",
    "    \"lr\" : 4e-4,\n",
    "    \"consis_coef\" : 100,\n",
    "    \"alpha\" : 0.1,\n",
    "}\n",
    "alg_cfg = ict_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc14b26-fb64-4996-bc83-81f057433f04",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635e3e0-1b46-47d2-b8b4-e0353df8f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICT(nn.Module):\n",
    "    def __init__(self, alpha, model, ema_factor):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mean_teacher = model\n",
    "        self.mean_teacher.train()\n",
    "        self.ema_factor = ema_factor\n",
    "        self.global_step = 0\n",
    "\n",
    "    def forward(self, x, y, model, mask):\n",
    "        self.global_step += 1 # for moving average coef\n",
    "        mask = mask.byte()\n",
    "        model.update_batch_stats(False)\n",
    "        mt_y = self.mean_teacher(x).detach()\n",
    "        u_x, u_y = x[mask], mt_y[mask]\n",
    "        l_x, l_y = x[mask==0], mt_y[mask==0]\n",
    "        lam = np.random.beta(self.alpha, self.alpha) # sample mixup coef\n",
    "        perm = torch.randperm(u_x.shape[0])\n",
    "        perm_u_x, perm_u_y = u_x[perm], u_y[perm]\n",
    "        mixed_u_x = lam * u_x + (1 - lam) * perm_u_x\n",
    "        mixed_u_y = (lam * u_y + (1 - lam) * perm_u_y).detach()\n",
    "        y_hat = model(torch.cat([l_x, mixed_u_x], 0)) # \"cat\" indicates to compute batch stats from full batches\n",
    "        loss = F.mse_loss(y_hat.softmax(1), torch.cat([l_y, mixed_u_y], 0).softmax(1), reduction=\"none\").sum(1)\n",
    "        # compute loss for only unlabeled data, but loss is normalized by full batchsize\n",
    "        loss = loss[l_x.shape[0]:].sum() / x.shape[0]\n",
    "        model.update_batch_stats(True)\n",
    "        return loss\n",
    "\n",
    "    def moving_average(self, parameters):\n",
    "        ema_factor = min(1 - 1 / (self.global_step), self.ema_factor)\n",
    "        for emp_p, p in zip(self.mean_teacher.parameters(), parameters):\n",
    "            emp_p.data = ema_factor * emp_p.data + (1 - ema_factor) * p.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58127e-4895-481b-aa10-cacd195bd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alg_cfg[\"lr\"])\n",
    "\n",
    "trainable_paramters = sum([p.data.nelement() for p in model.parameters()])\n",
    "print(\"trainable parameters : {}\".format(trainable_paramters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3263b-ef67-413a-aa1c-e818b4b87f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "t_model.load_state_dict(model.state_dict())\n",
    "ssl_obj = ICT(alg_cfg[\"alpha\"], t_model, alg_cfg[\"ema_factor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e92f64-f9e8-4dae-a47b-385c62847f27",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8a21d-4860-4e92-839f-a261ca054a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "ict_cls_loss_list = []\n",
    "ict_ssl_loss_list = []\n",
    "ict_loss_list = []\n",
    "\n",
    "ict_val_acc_list = []\n",
    "###\n",
    "\n",
    "iteration = 0\n",
    "maximum_val_acc = 0\n",
    "s = time.time()\n",
    "for l_data, u_data in zip(l_loader, u_loader):\n",
    "    iteration += 1\n",
    "    l_input, target = l_data\n",
    "    l_input, target = l_input.to(device).float(), target.to(device).long()\n",
    "\n",
    "    u_input, dummy_target = u_data\n",
    "    u_input, dummy_target = u_input.to(device).float(), dummy_target.to(device).long()\n",
    "\n",
    "    target = torch.cat([target, dummy_target], 0)\n",
    "    unlabeled_mask = (target == -1).float()\n",
    "\n",
    "    inputs = torch.cat([l_input, u_input], 0)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # ramp up exp(-5(1 - t)^2)\n",
    "    coef = alg_cfg[\"consis_coef\"] * math.exp(-5 * (1 - min(iteration/shared_config[\"warmup\"], 1))**2)\n",
    "    ssl_loss = ssl_obj(inputs, outputs.detach(), model, unlabeled_mask) * coef\n",
    "\n",
    "    # supervised loss\n",
    "    cls_loss = F.cross_entropy(outputs, target, reduction=\"none\", ignore_index=-1).mean()\n",
    "\n",
    "    loss = cls_loss + ssl_loss\n",
    "    \n",
    "    ###\n",
    "    ict_cls_loss_list.append(cls_loss)\n",
    "    ict_ssl_loss_list.append(ssl_loss)\n",
    "    ict_loss_list.append(loss)\n",
    "    ###\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 표기\n",
    "    if iteration == 1 or (iteration % 100) == 0:\n",
    "        wasted_time = time.time() - s\n",
    "        rest = (shared_config[\"iteration\"] - iteration)/100 * wasted_time / 60\n",
    "        print(\"iteration [{}/{}] cls loss : {:.6e}, SSL loss : {:.6e}, coef : {:.5e}, time : {:.3f} iter/sec, rest : {:.3f} min, lr : {}\".format(\n",
    "            iteration, shared_config[\"iteration\"], cls_loss.item(), ssl_loss.item(), coef, 100 / wasted_time, rest, optimizer.param_groups[0][\"lr\"]),\n",
    "            \"\\r\", end=\"\")\n",
    "        s = time.time()\n",
    "        \n",
    "    # Validation\n",
    "    if (iteration % args.validation) == 0 or iteration == shared_config[\"iteration\"]:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            print()\n",
    "            print(\"### validation ###\")\n",
    "            sum_acc = 0.\n",
    "            s = time.time()\n",
    "            for j, data in enumerate(val_loader):\n",
    "                input, target = data\n",
    "                input, target = input.to(device).float(), target.to(device).long()\n",
    "\n",
    "                output = model(input)\n",
    "\n",
    "                pred_label = output.max(1)[1]\n",
    "                sum_acc += (pred_label == target).float().sum()\n",
    "                if ((j+1) % 10) == 0:\n",
    "                    d_p_s = 10/(time.time()-s)\n",
    "                    print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                        j+1, len(val_loader), d_p_s, (len(val_loader) - j-1)/d_p_s\n",
    "                    ), \"\\r\", end=\"\")\n",
    "                    s = time.time()\n",
    "            acc = sum_acc/float(len(val_dataset))\n",
    "            print()\n",
    "            print(\"varidation accuracy : {}\".format(acc))\n",
    "            \n",
    "            ###\n",
    "            ict_val_acc_list.append(acc)\n",
    "            ###\n",
    "            \n",
    "            # Test\n",
    "            if maximum_val_acc < acc:\n",
    "                print(\"### test ###\")\n",
    "                maximum_val_acc = acc\n",
    "                sum_acc = 0.\n",
    "                s = time.time()\n",
    "                for j, data in enumerate(test_loader):\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device).float(), target.to(device).long()\n",
    "                    output = model(input)\n",
    "                    pred_label = output.max(1)[1]\n",
    "                    sum_acc += (pred_label == target).float().sum()\n",
    "                    if ((j+1) % 10) == 0:\n",
    "                        d_p_s = 100/(time.time()-s)\n",
    "                        print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                            j+1, len(test_loader), d_p_s, (len(test_loader) - j-1)/d_p_s\n",
    "                        ), \"\\r\", end=\"\")\n",
    "                        s = time.time()\n",
    "                print()\n",
    "                test_acc = sum_acc / float(len(test_dataset))\n",
    "                print(\"test accuracy : {}\".format(test_acc))\n",
    "                # torch.save(model.state_dict(), os.path.join(args.output, \"best_model.pth\"))\n",
    "        model.train()\n",
    "        s = time.time()\n",
    "        \n",
    "    # lr decay\n",
    "    if iteration == shared_config[\"lr_decay_iter\"]:\n",
    "        optimizer.param_groups[0][\"lr\"] *= shared_config[\"lr_decay_factor\"]    \n",
    "        \n",
    "print(\"test acc : {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9d5aa-7785-4828-b6c5-bbbc380d82bc",
   "metadata": {},
   "source": [
    "## 5. MixMatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeba2038-65b8-47dd-b152-b2afa583a526",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/35906602/209689424-e0675460-c8ac-473e-9286-1713a9f8cf28.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e406b5-8b36-48d5-95ff-3cabcee0c9d1",
   "metadata": {},
   "source": [
    "* Reference : https://jiwunghyun.medium.com/semi-supervised-learning-%EC%A0%95%EB%A6%AC-a7ed58a8f023\n",
    "* David Berthelot et al. MixMatch: A Holistic Approach for Semi-Supervised Learning. NeurIPS 2019.\n",
    "\n",
    "앞에 나온 entropy minimization, label consistency regularization, mixup을 모두 적용한 방법입니다. MixMatch는 labeled data와 unlabeled data를 받아서 결합된 데이터를 만듭니다.\n",
    "\n",
    "Unlabeled data에 대하여 K번의 augmentation을 하고 prediction의 평균을 구하고 그 값을 temperature sharpening을 통하여 sharpen 하며, Augmentation된 labeled, unlabeled 데이터를 섞고, 그 데이터에 대하여 labeled data와 unlabeled data에 MixUp을 합니다.\n",
    "\n",
    "학습은 다른 모델과 같이 supervised loss는 CE, unsupervised loss는 모델 출력 값의 차이 (L2)가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a0541-5496-4908-8081-689efa9ae92a",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be57947-b30d-4c94-b64e-180daf7685e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alg = 'MM'\n",
    "mm_config = {\n",
    "    # mixmatch\n",
    "    \"lr\" : 3e-3,\n",
    "    \"consis_coef\" : 100,\n",
    "    \"alpha\" : 0.75,\n",
    "    \"T\" : 0.5,\n",
    "    \"K\" : 2,\n",
    "}\n",
    "alg_cfg = mm_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f32a5-ab10-4ec3-99c8-67d680f801df",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be408b7-5ba4-49b2-961b-8bf75f3a6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixMatch(nn.Module):\n",
    "    def __init__(self, temperature, n_augment, alpha):\n",
    "        super().__init__()\n",
    "        self.T = temperature\n",
    "        self.K = n_augment\n",
    "        self.beta_distirb = torch.distributions.beta.Beta(alpha, alpha)\n",
    "\n",
    "    def sharpen(self, y):\n",
    "        y = y.pow(1/self.T)\n",
    "        return y / y.sum(1,keepdim=True)\n",
    "\n",
    "    def forward(self, x, y, model, mask):\n",
    "        # NOTE: this implementaion uses mixup for only unlabeled data\n",
    "        model.update_batch_stats(False)\n",
    "        u_x = x[mask == 1]\n",
    "        # K augmentation and make prediction labels\n",
    "        u_x_hat = [u_x for _ in range(self.K)]\n",
    "        y_hat = sum([model(u_x_hat[i]).softmax(1) for i in range(len(u_x_hat))]) / self.K\n",
    "        y_hat = self.sharpen(y_hat)\n",
    "        y_hat = y_hat.repeat(len(u_x_hat), 1)\n",
    "        # mixup\n",
    "        u_x_hat = torch.cat(u_x_hat, 0)\n",
    "        index = torch.randperm(u_x_hat.shape[0])\n",
    "        shuffled_u_x_hat, shuffled_y_hat = u_x_hat[index], y_hat[index]\n",
    "        lam = self.beta_distirb.sample().item()\n",
    "        # lam = max(lam, 1-lam)\n",
    "        mixed_x = lam * u_x_hat + (1-lam) * shuffled_u_x_hat\n",
    "        mixed_y = lam * y_hat + (1-lam) * shuffled_y_hat.softmax(1)\n",
    "        # mean squared error\n",
    "        loss = F.mse_loss(model(mixed_x), mixed_y)\n",
    "        model.update_batch_stats(True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f43afc-e357-4a07-989b-fdc95ddff2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wrn.WRN(2, dataset_cfg[\"num_classes\"], transform_fn).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alg_cfg[\"lr\"])\n",
    "\n",
    "trainable_paramters = sum([p.data.nelement() for p in model.parameters()])\n",
    "print(\"trainable parameters : {}\".format(trainable_paramters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cfc6a-440f-4229-98be-e34e4767f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_obj = MixMatch(alg_cfg[\"T\"], alg_cfg[\"K\"], alg_cfg[\"alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfb153-6902-4273-82d8-2c5438c8b88c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3315f-f468-4b32-9f40-cdf1cc4db7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "mm_cls_loss_list = []\n",
    "mm_ssl_loss_list = []\n",
    "mm_loss_list = []\n",
    "\n",
    "mm_val_acc_list = []\n",
    "###\n",
    "\n",
    "iteration = 0\n",
    "maximum_val_acc = 0\n",
    "s = time.time()\n",
    "for l_data, u_data in zip(l_loader, u_loader):\n",
    "    iteration += 1\n",
    "    l_input, target = l_data\n",
    "    l_input, target = l_input.to(device).float(), target.to(device).long()\n",
    "\n",
    "    u_input, dummy_target = u_data\n",
    "    u_input, dummy_target = u_input.to(device).float(), dummy_target.to(device).long()\n",
    "\n",
    "    target = torch.cat([target, dummy_target], 0)\n",
    "    unlabeled_mask = (target == -1).float()\n",
    "\n",
    "    inputs = torch.cat([l_input, u_input], 0)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # ramp up exp(-5(1 - t)^2)\n",
    "    coef = alg_cfg[\"consis_coef\"] * math.exp(-5 * (1 - min(iteration/shared_config[\"warmup\"], 1))**2)\n",
    "    ssl_loss = ssl_obj(inputs, outputs.detach(), model, unlabeled_mask) * coef\n",
    "\n",
    "    # supervised loss\n",
    "    cls_loss = F.cross_entropy(outputs, target, reduction=\"none\", ignore_index=-1).mean()\n",
    "\n",
    "    loss = cls_loss + ssl_loss\n",
    "    \n",
    "    ###\n",
    "    mm_cls_loss_list.append(cls_loss)\n",
    "    mm_ssl_loss_list.append(ssl_loss)\n",
    "    mm_loss_list.append(loss)\n",
    "    ###\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 표기\n",
    "    if iteration == 1 or (iteration % 100) == 0:\n",
    "        wasted_time = time.time() - s\n",
    "        rest = (shared_config[\"iteration\"] - iteration)/100 * wasted_time / 60\n",
    "        print(\"iteration [{}/{}] cls loss : {:.6e}, SSL loss : {:.6e}, coef : {:.5e}, time : {:.3f} iter/sec, rest : {:.3f} min, lr : {}\".format(\n",
    "            iteration, shared_config[\"iteration\"], cls_loss.item(), ssl_loss.item(), coef, 100 / wasted_time, rest, optimizer.param_groups[0][\"lr\"]),\n",
    "            \"\\r\", end=\"\")\n",
    "        s = time.time()\n",
    "        \n",
    "    # Validation\n",
    "    if (iteration % args.validation) == 0 or iteration == shared_config[\"iteration\"]:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            print()\n",
    "            print(\"### validation ###\")\n",
    "            sum_acc = 0.\n",
    "            s = time.time()\n",
    "            for j, data in enumerate(val_loader):\n",
    "                input, target = data\n",
    "                input, target = input.to(device).float(), target.to(device).long()\n",
    "\n",
    "                output = model(input)\n",
    "\n",
    "                pred_label = output.max(1)[1]\n",
    "                sum_acc += (pred_label == target).float().sum()\n",
    "                if ((j+1) % 10) == 0:\n",
    "                    d_p_s = 10/(time.time()-s)\n",
    "                    print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                        j+1, len(val_loader), d_p_s, (len(val_loader) - j-1)/d_p_s\n",
    "                    ), \"\\r\", end=\"\")\n",
    "                    s = time.time()\n",
    "            acc = sum_acc/float(len(val_dataset))\n",
    "            print()\n",
    "            print(\"varidation accuracy : {}\".format(acc))\n",
    "            \n",
    "            ###\n",
    "            mm_val_acc_list.append(acc)\n",
    "            ###\n",
    "            \n",
    "            # Test\n",
    "            if maximum_val_acc < acc:\n",
    "                print(\"### test ###\")\n",
    "                maximum_val_acc = acc\n",
    "                sum_acc = 0.\n",
    "                s = time.time()\n",
    "                for j, data in enumerate(test_loader):\n",
    "                    input, target = data\n",
    "                    input, target = input.to(device).float(), target.to(device).long()\n",
    "                    output = model(input)\n",
    "                    pred_label = output.max(1)[1]\n",
    "                    sum_acc += (pred_label == target).float().sum()\n",
    "                    if ((j+1) % 10) == 0:\n",
    "                        d_p_s = 100/(time.time()-s)\n",
    "                        print(\"[{}/{}] time : {:.1f} data/sec, rest : {:.2f} sec\".format(\n",
    "                            j+1, len(test_loader), d_p_s, (len(test_loader) - j-1)/d_p_s\n",
    "                        ), \"\\r\", end=\"\")\n",
    "                        s = time.time()\n",
    "                print()\n",
    "                test_acc = sum_acc / float(len(test_dataset))\n",
    "                print(\"test accuracy : {}\".format(test_acc))\n",
    "                # torch.save(model.state_dict(), os.path.join(args.output, \"best_model.pth\"))\n",
    "        model.train()\n",
    "        s = time.time()\n",
    "        \n",
    "    # lr decay\n",
    "    if iteration == shared_config[\"lr_decay_iter\"]:\n",
    "        optimizer.param_groups[0][\"lr\"] *= shared_config[\"lr_decay_factor\"]    \n",
    "        \n",
    "print(\"test acc : {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78852cc1-cd49-4914-80a5-c8be86b0395f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
